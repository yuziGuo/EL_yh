2021-01-08 15:08:06,759 - task_col_classifier.py [line:238] - INFO: args: {'mask_mode': 'crosswise', 'pooling': 'avg-cell-seg', 'seq_len': 90, 'pretrained_model_path': './models/bert_model.bin-000', 'vocab_path': 'models/google_uncased_en_vocab.txt', 'vocab': <uer.utils.vocab.Vocab object at 0x7f1f193603c8>, 'emb_size': 768, 'embedding': 'tab', 'encoder': 'bert', 'subword_type': 'none', 'tokenizer': <uer.utils.tokenizer.BertTokenizer object at 0x7f1df754ad68>, 'feedforward_size': 3072, 'hidden_size': 768, 'heads_num': 12, 'layers_num': 12, 'learning_rate': 2e-05, 'warmup': 0.1, 'batch_size': 32, 'dropout': 0.1, 'device': device(type='cuda'), 'epochs_num': 8, 't2d_path': './data/aida/ff_no_dup_test_samples_t2d', 'limaye_path': './data/aida/ff_no_dup_test_samples_limaye', 'wiki_path': './data/aida/ff_no_dup_test_samples_wikipedia', 'train_path': './data/aida/ff_train_samples', 'labels_map': {'MovieDirector': 0, 'AcademicJournal': 1, 'City': 2, 'University': 3, 'Saint': 4, 'RadioStation': 5, 'Newspaper': 6, 'Mountain': 7, 'Plant': 8, 'Currency': 9, 'PoliticalParty': 10, 'MountainRange': 11, 'Monarch': 12, 'VideoGame': 13, 'AdministrativeRegion': 14, 'Mammal': 15, 'Wrestler': 16, 'Bird': 17, 'Hospital': 18, 'BaseballPlayer': 19, 'Film': 20, 'Genre': 21, 'Airline': 22, 'Company': 23, 'Book': 24, 'Building': 25, 'Continent': 26, 'SportsTeam': 27, 'Writer': 28, 'Scientist': 29, 'Museum': 30, 'Mayor': 31, 'Country': 32, 'Lake': 33, 'GovernmentType': 34, 'Airport': 35, 'Language': 36}, 'labels_num': 37, 'logger': <Logger detail (DEBUG)>, 'logger_2': <Logger results (DEBUG)>, 'report_steps': 100}
2021-01-08 15:08:12,588 - task_col_classifier.py [line:243] - INFO: Model sent to device: cuda:0/cuda
2021-01-08 15:08:57,477 - task_col_classifier.py [line:225] - INFO: Epoch id: 1, Training steps: 100, Avg loss: 2.991
2021-01-08 15:09:21,535 - task_col_classifier.py [line:225] - INFO: Epoch id: 1, Training steps: 200, Avg loss: 0.622
2021-01-08 15:09:45,646 - task_col_classifier.py [line:225] - INFO: Epoch id: 1, Training steps: 300, Avg loss: 1.567
2021-01-08 15:10:09,448 - task_col_classifier.py [line:225] - INFO: Epoch id: 1, Training steps: 400, Avg loss: 2.146
2021-01-08 15:10:33,368 - task_col_classifier.py [line:225] - INFO: Epoch id: 1, Training steps: 500, Avg loss: 1.973
2021-01-08 15:10:57,269 - task_col_classifier.py [line:225] - INFO: Epoch id: 1, Training steps: 600, Avg loss: 1.368
2021-01-08 15:11:21,172 - task_col_classifier.py [line:225] - INFO: Epoch id: 1, Training steps: 700, Avg loss: 1.169
2021-01-08 15:11:45,080 - task_col_classifier.py [line:225] - INFO: Epoch id: 1, Training steps: 800, Avg loss: 0.043
2021-01-08 15:12:09,067 - task_col_classifier.py [line:225] - INFO: Epoch id: 1, Training steps: 900, Avg loss: 0.716
2021-01-08 15:12:27,971 - task_col_classifier.py [line:205] - INFO: Epoch_id: 1	 DataSet: ff_no_dup_test_samples_t2d	Acc: 0.045112781954887216
2021-01-08 15:12:52,056 - task_col_classifier.py [line:225] - INFO: Epoch id: 2, Training steps: 100, Avg loss: 3.958
2021-01-08 15:13:15,898 - task_col_classifier.py [line:225] - INFO: Epoch id: 2, Training steps: 200, Avg loss: 2.837
2021-01-08 15:13:39,766 - task_col_classifier.py [line:225] - INFO: Epoch id: 2, Training steps: 300, Avg loss: 2.023
2021-01-08 15:14:03,750 - task_col_classifier.py [line:225] - INFO: Epoch id: 2, Training steps: 400, Avg loss: 1.185
2021-01-08 15:14:28,069 - task_col_classifier.py [line:225] - INFO: Epoch id: 2, Training steps: 500, Avg loss: 0.697
2021-01-08 15:14:52,026 - task_col_classifier.py [line:225] - INFO: Epoch id: 2, Training steps: 600, Avg loss: 0.482
2021-01-08 15:15:16,093 - task_col_classifier.py [line:225] - INFO: Epoch id: 2, Training steps: 700, Avg loss: 0.337
2021-01-08 15:15:40,252 - task_col_classifier.py [line:225] - INFO: Epoch id: 2, Training steps: 800, Avg loss: 0.243
2021-01-08 15:16:04,404 - task_col_classifier.py [line:225] - INFO: Epoch id: 2, Training steps: 900, Avg loss: 0.226
2021-01-08 15:16:23,409 - task_col_classifier.py [line:205] - INFO: Epoch_id: 2	 DataSet: ff_no_dup_test_samples_t2d	Acc: 0.8571428571428571
2021-01-08 15:16:47,843 - task_col_classifier.py [line:225] - INFO: Epoch id: 3, Training steps: 100, Avg loss: 0.226
2021-01-08 15:17:11,990 - task_col_classifier.py [line:225] - INFO: Epoch id: 3, Training steps: 200, Avg loss: 0.142
2021-01-08 15:17:36,094 - task_col_classifier.py [line:225] - INFO: Epoch id: 3, Training steps: 300, Avg loss: 0.116
2021-01-08 15:18:00,251 - task_col_classifier.py [line:225] - INFO: Epoch id: 3, Training steps: 400, Avg loss: 0.106
2021-01-08 15:18:24,473 - task_col_classifier.py [line:225] - INFO: Epoch id: 3, Training steps: 500, Avg loss: 0.104
2021-01-08 15:18:48,622 - task_col_classifier.py [line:225] - INFO: Epoch id: 3, Training steps: 600, Avg loss: 0.087
2021-01-08 15:19:12,768 - task_col_classifier.py [line:225] - INFO: Epoch id: 3, Training steps: 700, Avg loss: 0.087
2021-01-08 15:19:36,916 - task_col_classifier.py [line:225] - INFO: Epoch id: 3, Training steps: 800, Avg loss: 0.078
2021-01-08 15:20:01,007 - task_col_classifier.py [line:225] - INFO: Epoch id: 3, Training steps: 900, Avg loss: 0.072
2021-01-08 15:20:20,141 - task_col_classifier.py [line:205] - INFO: Epoch_id: 3	 DataSet: ff_no_dup_test_samples_t2d	Acc: 0.8947368421052632
2021-01-08 15:20:44,731 - task_col_classifier.py [line:225] - INFO: Epoch id: 4, Training steps: 100, Avg loss: 0.082
2021-01-08 15:21:09,178 - task_col_classifier.py [line:225] - INFO: Epoch id: 4, Training steps: 200, Avg loss: 0.057
2021-01-08 15:21:33,637 - task_col_classifier.py [line:225] - INFO: Epoch id: 4, Training steps: 300, Avg loss: 0.054
